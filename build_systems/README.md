# Системы сборки

Когда Вы пишете или будете писать статью в LaTeX, собирать огромный C++ проект,
подключать модули в Python или Go, Вы столкнётесь с тем, что Вам нужно будет
применить систему сборки, которая уже в свою очередь вызывает интерпретаторы
или компиляторы. Системы сборки это в какой-то степени тоже программирование,
тем не менее, их чаще называют _метапрограммированием_, потому что Вы работаете
скорее с процессами, нежели пишете сам код &mdash; они объединяют множество модулей
воедино, создавая универсальную магию, когда одна команда порождает тысячи
других, граф начинает исполняться, и Вы радостно смотрите, как проходит сборка
миллион строк кода на Вашем компьютере за несколько минут.

Например, Google и Yandex имеют свои навороченные системы сборки с кэшами,
облачным хранением, показывая тем самым, что это всё ещё животрепещущая тема со
многими нерешёнными вопросами в их расширяемости и стабильности. Оно настолько
заботит разработчиков, что, например, Google переписал как минимум 4 раза свою
систему сборки [Bazel](https://bazel.build/) прежде чем ей стало действительно
удобно пользоваться. На это были убиты годы разработки и одни из самых лучших
инженеров. Это всё выродилось в то, что около 83% (данные из
[этой книги](https://www.amazon.com/Software-Engineering-Google-Lessons-Programming/dp/1492082791))
из разработчиков любят систему сборки больше всего помимо еды в офисе.

Каноничное метапрограммирование очень сложное и имеет свою собственную культуру
со своими негласными правилами и практиками, например, пакеты в apt или brew надо
собирать очень определённым образом. Лично я видел только несколько людей,
которые умеют это делать на "профессиональном" уровне. Тем не менее, полезно
знать что происходит для сбора пакетов низкоуровнево, а на следующих лекциях мы
наконец-то раскроем немного магии, что происходит с самими пакетными
менеджерами.

Во всех системах сборки Вы увидите несколько универсальных понятий, которые
используются повсеместно:

1. Targets. Это просто названия/имена того, что надо собирать.
1. Rules. Правила по которым стоит собирать уже Targets, обычно их единицы,
например, сборка C++ файла.
1. Dependencies. Зависимости, что нужно собрать до этого, чтобы уметь собирать
target. Часто это называют графом зависимостей, так как одни зависимости требуют
другие зависимости, а одинаковые зависимости ещё надо склеить в одни, чтобы
избежать двойной пересборки, ошибок правил одного инстанцирования и т.д.
1. Toolchain. Это самый базовый набор инструментов для сбора Targets и вызовов
Rules, например, компилятор и линкер в сборке C++ проектов.
1. Декларативность. Хорошо, если системы сборки не Тьюринг полны, они запрещают
делать всё что угодно пользователям. К сожалению, из рассмотренных только bazel
обладает этим свойством (и то, под вопросом). Декларативность правил позволяет
лучше контролировать зависимости и просто проще для рефакторингов и последующих
миграций.

То есть системы сборки можно представить как ацикличный граф Targets, каждый
из которых собирается каким-то Rule с помощью Toolchain, а Dependencies
определяют рёбра этого графа.

# Кэширование

Каждая уважающая себя система сборки не пересобирает всё с нуля, ибо это было бы
очень долго и затратно. Все вершины ацикличного графа пересобираются, если
только поменялись его зависимости, например, исходный код какого-то файла или
объектный файл при сборке. Если Вы используйте систему сборки и там нет
кэширования, можете смело выкидывать её из своего рассмотрения.

Ещё более интересные системы сборки нормализуют код, чтобы пересборка никогда
не была болезненной, если Вы добавили/удалили комментарий в коде или добавили
пару пробелов. Про LLVM мы поговорим в этом курсе.

# Параллелизация

Системы сборки отлично себя показывают в парадигме data parallelization, если
Вы собираете код. Все языки имеют модульную систему сборки, то есть условно
Вы скорее собираете тысячи мелких файлов, чем несколько очень больших. Из-за
этого, с ростом числа ядер в процессорах, достаточно свободно можно брать и
назначать этим ядрам выполнение каких-то задач, когда данные не пересекаются.
По-простому это означает, что раз таргеты независимы, значит их можно собирать
параллельно, а практика показывает, что самый низкий уровень (когда мы собираем
просто файлы с кодом) намного больше по сравнению с остальным графом и от его
оптимизаций можно получить самый большой прирост.

Представление работы в виде графа исполнения всё больше и больше приобретает
популярность, так в Yandex есть система [Nirvana](https://habr.com/ru/company/yandex/blog/351016/),
которая в основном используется аналитиками для визуального представления графа
и его исполнения, а в Google есть [Google Cloud Dataflow](https://cloud.google.com/dataflow),
который подходит для тех же задач, а также стал расширением MapReduce парадигмы
(которая, впрочем, уже __реально устарела__), где Вы просто описываете что Вы
хотите сделать с данными (возможно не только Map и Reduce операции, но и другие
как Join, Flatten, GroupBy, Sort, etc), строится граф, сам оптимизируется,
исполняется и выдаёт результат пользователю.
[YT](https://habr.com/ru/company/yandex/blog/311104/), к сожалению, такого не
может и графы нужно строить самим, возможно через ту же Nirvana или shell
скрипты.

# make

Давайте уже рассматривать сами системы сборки. Одной из самых первых и уже
стандартных систем сборки в UNIX системах можно считать `make`. Система, если
говорить по-хорошему, устаревшая и имеет множество недостатков. Но для
повседневной разработки она достаточно простая. Чтобы ею пользоваться, стоит
создать файл `Makefile`. Давайте посмотрим на какой-нибудь простой пример:

```make
paper.pdf: paper.tex plot-data.png
	pdflatex paper.tex

plot-%.png: %.dat plot.py
	./plot.py -i $*.dat -o $@
```

Зависимости в правой части перечисляются через пробел. Также можно указывать
слева и справа так называемые [паттерны](https://www.gnu.org/software/make/manual/html_node/Pattern-Intro.html#Pattern-Intro),
которые могут содержать не более одного символа `%`, они демонстрируют любую
подстроку для сбора таргета, например, потом можно будет делать
`make plot-me.png` и `make plot-you.png`. Само описание правил (или как в
терминологии make, _рецепта_) можно иcпользовать эти паттерны в достаточно
изощренном виде &mdash; все такие токены начинаются с `$`, как в bash и обозначают
следующее

- `$@`: имя таргета, при `make plot-data.png` это будет `plot-data.png`
- `$%`: имя так называемых архивов, например, статических файлов, описание
таких таргетов происходит как `plot-%.png(some-library.o): deps...`, то `$%` это
`some-library.o`
- `$*`: матчит полный путь к файлу по зависимостям. В данном случая оно просто
берёт строку `data` при `make plot-data.png`, и чуть более хитрые правила при
рекурсивных вызовах.

Если честно, я почти каждый раз обращаюсь к [документации](https://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html)
по всем этим правилам, синтаксис у них абсолютно ужасный и неинтуитивный.

К сожалению, всё ядро Linux собирается через Makefile, и лично для меня патчи в
Linux самые сложные из-за каких-то нетривиальных зависимостей в этих самых
Makefile.

Давайте попробуем запустить `make`. Стоит отметить, что при обычном запуске
будут собираться все файлы сразу, а при `make target` только `target`, будьте
осторожны в больших проектах, если Вам нужен только специфичный подпроект, не
надо собирать всё, потратите только время.

```console
$ make
make: *** No rule to make target 'paper.tex', needed by 'paper.pdf'.  Stop.
```

Оно и понятно, у нас нет файла `paper.tex`, возьмём [его](./paper.tex).

Теперь `make` будет падать с такой ошибкой:

```console
$ make
make: *** No rule to make target 'plot-data.png', needed by 'paper.pdf'.  Stop.
```

Ладно, давайте уж наконец создадим все файлы.

```console
$ make
./plot.py -i data.dat -o plot-data.png
pdflatex paper.tex
... lots of output ...
```

Отлично, мы собрали нашу pdf. Теперь если мы ещё раз соберём, то уже получим
сообщение

```console
$ make
make: 'paper.pdf' is up to date.
```

Это кэширование работает, как и было рассказано выше. При изменении файлов будет
смотреться их дата изменения и решение будет приниматься из этого.

`make` действительно устарел, но на нём уже столько кода, что уже невозможно
это искоренить. Основные потребители `make` - это скорее C репозитории. Стоит
помнить, что негласно в `make` придерживаются следующих опций для сборки C
кода, например,

- `CC, CXX` &mdash; компиляторы C и C++ соответственно. Например, можно запускать
`CC=clang CXX=clang++ make`, а в `Makefile` к этим переменным обращаются как к
`$(CC)` и `$(CXX)`
- `CFLAGS`, `CPPFLAGS` &mdash; опции компиляции C и C++ соответственно.
- `LDFLAGS` &mdash; опции линкера для сборки такого кода.

Другие наиболее полезные опции

- `-j 10` &mdash; запуск `make` на 10 ядрах, считается правильным запускать на числе
ядер минус 1, чтобы `make` имел ещё одно ядро для регулирования графа
- `VERBOSE=1` &mdash; показывание всех команд рецепта, полезно для воспроизведения
локального результата и дебага

Все опции `make` можно посмотреть [здесь](https://www.gnu.org/software/make/manual/html_node/Options-Summary.html).

# cmake, ninja, make

Чтобы решить проблему очень назойливого `make` и огромных похожих, но не совсем,
правил, была создана программа `cmake`. По итогу она оказалась всё равно
сложной с протекающими абстракциями, но её хотя бы можно освоить на уровне,
который поможет собирать достаточно уже сложные проекты. Почти любой уважающий
себя C++ проект имеет `CMakeLists.txt` в корневой директории. Типичные команды
для сборки CMake проектов такие:

```console
$ cd project
$ mkdir build
$ cd build
$ cmake ..
$ make -j $N # количество ядер минус один
```

То есть CMake генерирует большие `Makefile` для сборки проектов. После этого
можно уже собирать всё через `make`. Стандартные флаги для указания в CMake,
которые используются повсеместно при сборке

- `-DCMAKE_C_FLAGS=-one,-two` &mdash; C флаги
- `-DCMAKE_CXX_FLAGS=-one,-two` &mdash; C++ флаги
- `-DCMAKE_CXX_STANDARD=11,14,17,20` &mdash; версия стандарта для сборки
- `-DCMAKE_LINKER_FLAGS=-one,two` &mdash; флаги для линковки
- `-DCMAKE_BUILD_TYPE=Release|Debug|RelWithDebInfio|MinSizeRel` &mdash; указание
системы сборки, полная оптимизация, дебажная сборка (без оптимизаций),
оптимизация с дебажными символами (вспоминаем gdb), минимальная по размеру
соответственно. По умолчанию сборка почти во всех проектах __дебажная без
оптимизаций__.
- `-G "Ninja"` &mdash; использование системы ninja вместо make. **Я лично всегда
использую эту опцию, она стабильнее, лучше переиспользует cache и всё такое**. К
сожалению, в старых CMake версиях она не поддерживается. Все генераторы можно
посмотреть [здесь](https://cmake.org/cmake/help/v3.5/manual/cmake-generators.7.html#manual:cmake-generators(7)).

- `CC, CXX` переменные окружения так же задают дефолтные компиляторы.

Также Google выпустила свою систему сборки [ninja](https://ninja-build.org/),
которая в разы [проще](https://ninja-build.org/manual.html), имеет интеграцию с
CMake. Я предпочитаю её использовать там, где можно обойтись без `make`.
Аргументы по параллелизации одинаковые с `make`, у `ninja` &mdash; `-j N` флаг.

# CMake

Чем CMake так хорош? (ладно, на самом деле плох, я постараюсь как-то в хорошем
ключе эту систему сборки описать).

Тем, что CMake умеет достаточно легко подключать рекурсивные зависимости.

Таргеты в CMake это бинарные файлы и библиотеки, с ними всё достаточно просто
(они называются `add_executable` и `add_library`, потом название, потом исходные
файлы):

```cmake
add_executable(myExecutable
  main.cpp
)

add_library(libA
  source_a.cpp
)

add_library(libB
  source_b.cpp
  source_b_impl.cpp
)

add_library(libC
  source_c.cpp
)
```

Далее в C++ коде надо уметь линковать библиотеки, это делается с помощью
`target_link_libraries`:

```cmake
target_link_libraries(myExecutable libA)
target_link_libraries(libA libB)
target_link_libraries(libB libC)
```

`cmake` умеет раскрывать другие `cmake` файлы, например, через команду
`include`:

```cmake
include(cmake/find/other_project.cmake)
```

И рекурсивно подхватывать другие `CMakeLists.txt` в поддиректориях &mdash; это
делается с помощью `add_subdirectory`:

```cmake
add_subdirectory(zstd)
```

А чтобы подключить `#include` для видимости в проектах стоит написать
`target_include_directories`:

```cmake
target_include_directories(myproject <visibility> myproject/include)
```

Для использования макросов полезно знать ещё одну команду:

```cmake
target_compile_definitions(myproject <visibility> flag_1 flag_2)
```

`<visibility>` это опция для того, чтобы описать кому видны инклюды и флаги, существует три
вида:

- PRIVATE - только внутри собираемого таргета
- PUBLIC - все, кто линкуется с библиотекой, в том числе и с собой
- INTERFACE - все, кто линкуется с библиотекой, исключая себя

Перед `<visibility>` можно ещё написать `SYSTEM` &mdash; означает, что к хедерам
можно относиться как с системных хедерам, например, как в стандартной библиотеке
`#include <some/path.h>`, а не `#include "some/path.h"`. Полезно потом для
переопределения с системными хедерами, если библиотека нативно присутствует на
машине.

Также есть директива `set`, которая как в bash выставляет переменные, например

```cmake
set(DIR my/dir)
set(SRCS
   ${DIR}/src/a.cpp
   ${DIR}/src/b.cpp)
add_library(project ${SRCS})
```

Также для таргета Вы можете переопределять опции сборки, например,
`target_compile_options`. Чтобы посмотреть типичный CMake файл, можно обратиться
к [CMakeLists.txt](https://github.com/ClickHouse/ClickHouse/blob/fb0e68f808eb4e0d3bb2d889359aa11d871ab949/contrib/hyperscan-cmake/CMakeLists.txt)
в ClickHouse.

Поэтому CMake позволяет писать условия, устанавливать правила видимости,
подключать субдиректории, которые являются зависимостями. На лекции был пример,
как оно работает в действии, смотрите запись.

## Ещё про системы сборки

Как мы видим, make (да и другие системы, например, Ant) являются task-based:
Вы сами вольны собирать как угодно свои таргеты без какого либо присмотра, но
тогда все зависимости и корректность остаётся за Вами.

CMake уже больше поход на artifact-based: то есть даётся от силы сотня правил
сборки, а дальше Вы из этого собираете конструктор, где меньше есть свободы для
произвольного кода. Bazel, к примеру, пошёл совсем по пути, где даётся несколько
десятков правил и ничего кроме этих правил делать нельзя (максимум писать ещё
свои, если сильно надо).

В идеале каждый open-source проект должен показывать как стоит подключать
себя как зависимость и как его собирать. Обычно эта информация содержится в
README или в документации.

# Система зависимостей

CMake хорош тем, что зависимости можно достаточно легко подключать, тем не
менее, из-за философии языка C и C++ в том, что все библиотеки лучше собирать
с нуля и только самые популярные оставить с ABI совместимостью. Поэтому
большинство зависимостей ручные, надо обязательно иметь код под рукой. Так
неверно для языков Rust, Go, Python. В них Вы можете указывать библиотеки как
зависимости, какие версии можно использовать, а какие нельзя. Это приводит к
достаточно популярному понятию в системах зависимостей как
[sematic versioning](https://semver.org/). Я лично считаю эту систему
нерасширяемой, но на маленьких-средних проектах она приносит свои плоды.

В целом есть библиотеки, есть код, а в коде есть баги или хочется какую-то
новую функциональность добавить. Конечно, версии удобно инкрементировать
числами, тем не менее, бывают разные изменения, совместимые и не очень. Поэтому
SemVer сделали публикуемым тремя числами (major.minor.patch).

- Если Ваше изменение не меняет API, например, исправляет баги, то стоит
инкрементировать patch версию.
- Если Ваше изменение добавляет API или меняет его так, что оно обратно
совместимо, то это инкремент minor версии и обнуление patch версии
- Если Ваше изменение меняет API в несовместимом формате, инкремент major
версии, с обнулением minor и patch

Если major версия 0, обычно это означает, что проект ещё не готов к выкладке,
находится в стадии beta и к комментариям пользователей.

То есть переход с `1.3.38` до `1.3.56` или `1.6.4` должен быть безболезненным,
а переход с `1.3.38` до `2.1.23` уже возможно нет как и `2.1.23` до `2.0.7`.

Правила достаточно условные и, к сожалению, возникают ситуации, когда меняется
patch версия, а код ломается. Google, к примеру, избрал другую стратегию и
всегда живёт по стратегии live at head и каждый коммит проверяет все
зависимости, что они правильно работают. Больше подробностей можно посмотреть
[тут](https://www.youtube.com/watch?v=tISy7EJQPzI), если кратко, всё ломалось
c SemVer очень быстро на таких масштабах, а также разные клиенты требовали
разные зависимости, что выливалось в ошибки, когда таргет требовал два разных
API через две разных библиотеки. Это, к сожалению, проклятье всех больших
кодовых баз и проектов, поэтому SemVer не должен быть выбором, если кодовая
база на сотни тысяч или миллионы строк кода, например, система Bazel полностью
отказалась от SemVer из-за этого (если быть точным, то она проектировалась,
чтобы никогда не зависеть от SemVer).

С Live at Head получается, что нет проблем с обновлением и проверкой
корректности зависимостей. За это платим сложным обновлением и проверкой
низкоуровневых библиотек. На маленьких - средних масштабах SemVer работает хорошо,
на больших нет никаких вариантов, кроме как Live at Head.

Многие языки программирования и пакетные менеджеры, как я уже описал выше,
имеют свои системы сборки и зависимости в SemVer, так, в
[Rust](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html),
[Go](https://blog.golang.org/using-go-modules) и [Python](https://pip.pypa.io/en/stable/reference/pip_install/#requirements-file-format)
можно указывать SemVer зависимости, отрезки версий и так далее. Такие файлы
называются lock файлами. Они избавляют Вас от ручного обновления, но, как
говорилось выше, могут сломать Вам код (хаха, попробуйте обновиться с Tensorflow
1 до Tensorflow 2).

Если говорить про определение корректных условий систем зависимостей пакетов в
SemVer, то несложно доказать, что эта задача является
[NP-полной](https://research.swtch.com/version-sat) в произвольном графе
зависимостей.

Вообще, в целом, в индустрии очень любят нагородить фреймворков друг на друга,
а потом удивляться, почему ничего не работает или еле еле держится. Помните,
что с подключением зависимости идет огромная цена поддержки этой зависимости,
знание какими API пользуются, тестирование, чтобы ловить регрессии при
обновлении, разрастание проекта и зоны ответственности. Никогда не добавляйте
зависимость без тестирования Вашего продукта. В инженерном деле, как и в физике,
всё имеет свойство терять энергию без её поддержки, в данном случае,
тестирование и регрессии при обновлении.

# CI системы

С багами при обновлении могут автоматические тесты, которые тестируют (в идеале)
на каждый коммит изменения. Также проекты разрастаются, Вы уже не можете
контролировать код, быть уверенным, что Вы пишете код без багов. На помощь к
автоматизации таких процессов приходят тестирующие системы.

Их ещё называют CI (continuous integration) системами, которые обозначают
"запускаем что-то при любом изменении кода". Существуют много CI систем, github
предлагает какие-то свои, кто-то пользуется [TravisCI](https://travis-ci.org/),
[CircleCI](https://circleci.com/) или [Azure
Pipelines](https://azure.microsoft.com/en-us/services/devops/pipelines/). В
целом их наиболее популярный сценарий &mdash; что-то поменялось, запусти тесты. Или
есть код на код ревью, запусти тесты против этого кода. Мы ещё поговорим про
одну CI систему, и Вы должны будете сделать домашнее задание по ней.

Ещё Вы будете встречать на практике понятие CD (continuous delivery), это
считайте тоже самое, только оно обычно при всех "зелёных тестах" создаёт
кандидата на релиз. Вы можете сами настраивать, с какой частотой выпускается
новая версия, будь то на каждый коммит, раз в день, раз в неделю. Например, в
Facebook большинство сайта обновляется раз в 8 часов, то есть программист ждёт
порядка 1 рабочего дня, чтобы увидеть все изменения в коде. В Google это
отдаётся на откуп командам, но обычно релизы происходят раз/два в неделю/месяц.

Многие из Вас ещё будут ощущать на себе инженерную продуктивность и то, что
тесты долго работают, поэтому обычно в CI делают быстрые тесты или прогоняют
на каком-то subsample, чтобы потенциально выдать Вам упавшие тесты. Тем самым
больше вероятность, что Вы будете итерироваться, а когда такой быстрый тест
пройдёт, с большой вероятностью и все остальные пройдут.

CI системы рано или поздно становятся "флапающими" &mdash; это когда один и тот
же тест то проходит, то не проходит. К сожалению, мир не всегда детерминирован,
например, в сетевых технологиях или в многопоточном и распределённом
программировании, поэтому такие проблемы возникали и будут возникать. В такие
моменты стоит правильно настраивать мониторинг на то, что тесты упали, а то
со временем "замыливается" глаз и можно обнаружить, что тесты вообще не работали
или половина из них сломана, а никто и не заметил.

CI системы должны быть достаточно умными, например, находить виновников
упавшего теста, не всегда каждое изменение тестируется на всём наборе в целях
экономии времени и железа. Тогда запускается бинарный поиск и ищется виновник.
CI системы также могут откатывать автоматически изменения, которые сломали очень
много различных тестов, например, так могло произойти из-за merge conflict.

Стремиться к 100% "зелёным тестам" просто невозможно, как и гарантировать 100%
рабочую систему вроде поиска Яндекса или Гугла. 99.9% уже кажется более
реалистичным, но все фиксы багов должны быть скорее первым приоритетом, нежели
остальное. Например, можете посмотреть на [Cyberpunk](https://www.gamesradar.com/uk/cyberpunk-2077-bugs/).

То есть придерживайтесь такой стратегии, когда разрабатывайте любую программу:

* make it compile
* make it correct
* make it stable
* make it fast

# Коротко про тестирование

Тестирование является важным аспектом любой разработки (я бы сказал, что самым
важным). Писать код без багов не умеет никто, как бы Вы не старались. Тесты
ловят ошибки, иногда очень нетривиальные и помогают зафиксировать какое-то
поведение.

Одна хорошая история заключается в том, что Google поиск к 2005 году стал
настолько уже сложным, что примерно 80% изменений откатывались. Проблема была в
том, что не было хорошего тестирования и все изменения делались скорее на веру.
Через год после введения обязательного тестирования всех компонент, количество
откатов сократилось в 2 раза и количество нововведённых фичей выросло в 3 раза.

Тестирование позволяет покрывать следующие аспекты:

* Меньше дебагать, в том числе и в gdb :)
* Больше уверенности в изменениях
* Лучше документация
* Больше примеров использования API
* Лучше и чище абстракции, если их легко протестировать
* Быстрые релизы
* Ловля регресий при замене зависимостей

Существует несколько базовых видов тестирования:

- Unit тестирование. Мини-тесты, которые тестируют что-то в изоляции, какое-то
поведение системы.
- Integration тестирование. Тестирование всей системы, например, обстрел базы
данных или выкладка на тестирующий контур.
- Functional тестирование. Тестирование e2e функциональности. Например,
единичные запросы к базе данных.
- Regression тестирование. Тестирование каких-то метрик, бывших падений системы,
которые позволяют замерять, что поменялось на метауровне программ, или, чтобы
предотвратить последующих падений.
- Mock тестирование. Когда имплементация функции или какой-то функциональности
заменяется на тестирующую функцию &mdash; тестируется, что функции вызываются с
определёнными параметрами, столько раз в определённом порядке.
- Smoke тестирование. Когда тестируется какая-то совсем базовая функциональность
для тестирования уже большей, то есть, если она не проходит, значит что-то очень
фундаментально сломано.
- Fake тестирование. Создается более лёгкий контур, подменяющий какой-то сервис,
например, in-memory база данных, чтобы тестировать функциональность.
- Fuzz тестирование. Одно из современных направлений &mdash; генерируются очень
много запросов, которые пытаются увеличить контур и покрытие программы, чтобы
найти какие-то сложные места и там упасть. Обычно такие тесты просто работают
24/7 и просто сообщают об ошибках, если они есть.
- ~~Stress тестирование. Нет такого тестирования, забудьте.~~

На самом деле Stress тестирование тоже существует. Деление условное, и Вы можете
видеть разные градации, но в целом они сводятся
к каким-то общепринятым базовым. Не слушайте людей, которые Вас пытаются
убедить в каких-то особенностях градации, это не имеет большого смысла. Тесты
должны тестировать, а не быть точно классифицированы.

Иногда бывает, что Вы не можете что-то протестировать лично у себя и Вам нужно
A/B тестирование на пользователях. Хорошей практикой является поставить все
изменения под флаг, который умеет за __секунды__ отключаться или переливаться до
нуля. Это позволяет быстро итерироваться, находить проблемы и оставаться
незамеченным.

Тестирование это отдельное искусство, и на лекции мы разобрали несколько тестов
из кодовой базы Chromium и ClickHouse. Впрочем, даже за одну лекцию не
рассказать, как правильно тестировать тот или иной код, это годы разработки, с
которыми Вы в том или ином виде, скорее всего, столкнётесь.
