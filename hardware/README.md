# Железки

Вы покупаете ноутбуки, станции, сервера, все практически без исключения
достаточно похожи устроены, на них есть:

* Материнская плата
* Процессор
* Память RAM
* Диски. HDD или SSD
* Сетевая карта
* GPU
* Механизм охлаждения
* Графический вывод, a.k.a. мониторы или экраны (не у серверов)
* И так далее

Все из них имеют какую-то производительность, ответственны за какие-то действия.
Понятное дело, что каждая компонента имеет какие-то характеристики. Давайте
сначала о общих них и поговорим. Я не хочу лезть в физику, с самим железом Вам
скорее всего придётся работать редко, тем не менее, знать и понимать
характеристики важно, это всё про прикидку Ваших результатов и проектирования
сервисов, UI, чего угодно.

## Latency или задержка

Latency или задержка это просто время, сколько занимает то или иное действие. В
теории, это можно применить ко всему, но чаще применяют этот термин для
процессов в изоляции, например:

1. Какая задержка у запроса в поиск? А на 99-й квантили?
1. Сколько занимает времени отрисовка первого видео кадра на монитор
1. Какова latency похода в общую память?

Latency реже применяется к самим процессам, которые сложно изолировать, плохие
вопросы в себя включают:

1. Какая задержка при разыменовывании указателя? Ответ: зависит, есть кэши, есть
   общая память, сказать невозможно не зная как часто или редко разыменовывается
   указатель.

## Throughput или пропускная способность

Throughput показывает пропускную способность того или иного процесса

1. Сколько запросов может выдержать поисковая компонента?
1. Какая последовательная скорость чтения диска?
1. Сколько различных ядер одномоментно может выполнять процессор?

Плохие вопросы опять же в себя включают неоднозначность процесса:

1. Какова скорость процессора? Ответ: зависит от инструкций и программ, зависит
   от памяти и кэшей.

В целом, задавание правильных вопросов про характеристики приходит с опытом и
понимаем, какие процессы различаются и что требуется в самом железе. В физику
мы уходить не будем, я лишь хочу рассказать про основные характеристики и дать
числа, сколько занимают те или иные операции. Это поможет Вам в будущем легче
прикидывать количество операций и время, которое у Вас будет занимать
программа/код/запрос/что угодно.

Часто эти две метрики рассматривают в параллель и являются основными полагающими
для всей производительности программ. Конечно, самая интересная часть является
понимание, почему распределение такое и почему числа такие, для этого надо
спускаться вплоть до hardware и понимать какие операции сколько занимают.

## Закон Мура

Этот импирический закон был высказан Гордоном Муром в 1965 году, он говорит, что
количество транзисторов у процессоров вырастает в два раза каждые два года. К
самому большому удивлению, это остаётся правдой до сих пор и скорее всего будет
правдой как минимум до 2025 года

![Moore](https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Moore%27s_Law_Transistor_Count_1970-2020.png/1280px-Moore%27s_Law_Transistor_Count_1970-2020.png)

Этот закон хоть и имеет под собой сильную техническую составляющую, но он
является чуть более философским, потому что огромное количество hardware
подчинялось и подчиняется этому закону, например

1. Поверхностная площадь жёстких дисков увеличивается в два раза каждые два года.
   **1990-2010, дальше стало по 10-15%, последние годы всё сложнее**
1. Пропускная способность оптоволокна &mdash; количество битов в секунду,
   которое может быть отправлено по оптическому волокну, увеличивается
   экспоненциально, быстрее, чем закон Мура. Назван законом Кека. **Пока не
   планирует останавливаться до 2030-2035. Потенциально у каждого в доме спокойно
   могут существовать террабитные сети.**
1. Закон Баттерса гласит, что объем данных, поступающих по оптоволокну,
   удваивается каждые девять месяцев. Таким образом, стоимость передачи
   бита по оптической сети уменьшается вдвое каждые девять месяцев. **Не собирается
   останавливаться и не будет никаких проблем ещё долго.**
1. Количество пикселей за доллар увеличивается экспоненциально. **Правда до сих
   пор, будет правдой скорее всего ещё долго, проблема в том, что мы плохо
   умеем копьютерно обрабатывать такие сигналы. Если научимся, 128K телевизоры
   вполне будут существовать в каждом доме.**
1. Вставьте почти любую технологию и получите свой закон Мура.

Закон Мура не может существовать бесконечно, понятное дело, в некоторых областях
он начинает потихоньку умирать, в некоторых областях и так уже сложно
утилизировать технологии (например, 8K телевизоры).

Из этого нужно сделать один вывод: hardware за последние 20-30 лет выросло в
своей производительности в **тысячи, сотни тысяч, миллионы** раз. Это поистине
воодушевляющая революция, которая помогла нам иметь в кармане компьютер, который
в разы мощнее, чем любой компьютер в 1975 году. Это время, когда уже людей
посылали в космос.

Эта революция позволила нам иметь такие вещи, как Python, JS, Docker, бесконечное
количество места и так далее. Да и вообще весь big tech как Google, Amazon,
Facebook могут работать на таком масштабе из-за огромного развития hardware.

Итак, перейдём к рассмотрению самих частей и их возможностей на 2020-2021 год.
Будет обновляться со временем, если курс будет читаться.

## Процессоры

* Герцовость: фактически, количество тактов в секунду. Типичные значения
  2-2.6ГГЦ для серверов, 2.8-4ГГЦ для домашних компьютеров и ноутбуков.
* Типичные числа для процессора
  * Доступ к L1 кэшу &mdash; 1ns. Серверные размеры 512KB-2MB
  * Доступ к L2 кэшу &mdash; 4-6ns. Серверные размеры 2-8MB
  * Доступ к L3 кэшу &mdash; 10-60ns. Серверные размеры 45-256MB
  * Размер кэшлинии 64 байта
  * Неугадывание ветки &mdash; 3ns
  * Блокировка mutex в одном потоке &mdash; 17-18ns, линейный рост с количеством
    потоков
  * Использование AVX2 и так далее &mdash; понижение герцовости на 10-20%
  * Серверы 64-80 ядер, домашние 4-16 ядер
  * Прерывание &mdash; десятки микросекунд
  * TDP 50-100W для домашних, 150-300W для серверных
  * Процессор ошибается где-то раз в год

В процессорах все ещё увеличивают количество транзисторов при помощи уменьшение
размера gate, например, процессор M1 от Apple имеет размер одного в 5нм, мы
скорее всего в будущем увидим ещё пару уменьшений, но меньше 1.4нм будет уже
сложно из-за размера атома кремния.

Стоит также различать архитектуры x86, ARM, Power, MIPS и так далее. Какая
лучшая сказать сложно, у ARM точно больше возможностей быть более быстрым и
лучше подходящим для дальнейших уменьшений в отличие от x86 в котором размеры
инструкций варьируются. У Power очень сильная пропускная способность.

Почему бы не делать процессоры больше для увеличения количества транзисторов?
Потому что процессоры "печатаются" на специальных огромных платах, увеличивается
количество брака если резать процессоры больше, получается невыгодно
производителям.

## Память

Память не так стремительно развивается, сейчас в обиходе стандарт DDR4,
герцовость от 2133MHZ до 3200MHZ, больше &mdash; действительно экзотические
случаи и не все процессоры поддерживают. Память состоит из конденсаторов,
которые могут заряжаться и выставлять биты в 1 или терять заряд и ставить бит в
0. Эти заряды обновляются, памяти надо поддерживать состояние. При
падения электичества, память не сохраняется.

* Случайный доступ к общей памяти 100ns
* Типичные размеры памяти для серверов 128-512 GiB. Каждый stick RAM это 16GB,
  очень редко встречаются 32GB модули.
* Память ошибается достаточно часто, но для этого есть Error Correction Codes,
  когда доступ к памяти можно провалидировать с так называемыми парными битами
  (parity), как самый простой пример &mdash; у всех битов посчитать xor и
  сравнить
* Сжать 1KB каким-нибудь популярным алгоритмом где-то 1-2 микросекунды
  (1000-2000ns).

Про скорость RAM можно почитать по этой [ссылке](https://www.wepc.com/tips/ram-speed/).

1 GiB памяти примерно как 0.1 ядро. Память также ломается где-то раз в 4-5 лет.

## Диски

Здесь стоит разделять HDD и SSD. В первом случае есть ручка и катушки, которые
вращаются со скоростью 5200-7400 оборотов в секунду (больше &mdash; начинается
сильная вибрация и диски выходят быстрее из строя). Во втором NAND память
позволяет держать заряд несколько лет без его потери (то есть если Вы не будете
использовать SSD несколько лет, то данные могут потеряться). NVME это
технология SSD, которая позволяет лучше распределять запросы чтения и записи.
Про то, как работают HDD и SSD более подробно можно посчитать в ссылках внизу,
пока цифры:

* Случайный доступ HDD 5-10ms, NVME 16 микросекунд
* Прочитать последовательно 1MB после доступа HDD 1-3ms, NVME 40 микросекунд
* Скорость HDD 80-160MB/s, NVME 1.5-2GB/s
* NVME может где-то 300 тысяч до 1 миллиона случайных 4КБ чтений/записей в
  секунду, HDD лишь 70-100. Просто семьдесят-сто.
* NVME дороже в 20 раз, чем память
* NVME диски где-то максимум 1-4TB, жёсткие диски 2-10TB в датацентрах
* NVME всё дешевеет, например, года 2-3 назад, такое пространство стоило в 30
  раз дороже, чем память, сейчас уже где-то в 20
* NVME дороже HDD в \~30 раз, это всё снижается

## Сеть

* Throughput безграничен, недавно приняли стандарт по 800GiB/s, в датацентрах
  10-100GiB/s сейчас, в домах единицы гигабит максимум
* Средняя latency до ближайшего датацентра Google или Яндекса где-то 20-30ms
* Пересылка из Европы в Америку где-то 150ms. Из забавного, отрисовка первого
  кадра в 4K занимает примерно столько времени
* Пересылка пакета в том же датацентре 0.5ms

## Люди

* Мы начинаем замечать разницу задержки в 10ms, например, это где-то 1-3
  случайных доступов к HDD. 30 FPS vs 60 FPS заметно человеческому глазу
* Пользователи где-то при 100ms думают, что всё работает моментально, например,
  терминал должен работать очень шустро
* Отклик мышки и клавиатуры &mdash; 20-40ms
* Скорость реагирования человеком на изменение в районе 180-200ms
* 1-1.5 секунды это лимит, который пользователь готов ждать ответа и не особо
  заметит. К примеру, поиск в Google и Yandex старается отвечать за
  полсекунды или 800 миллисекунд.
* 10 секунд это максимальный лимит посмотреть в экран в одну точку и дождаться
  результата у среднего пользователя. Если оно не работает дольше, скорее всего
  закроют вкладку и подумают, что ничего не работает
* 1 минута это максимум для важных операций, например, перевод денег в банке
* 10 минут это средняя сессия на сайте
* 1-2 часа это ожидание какого-то большого результата, например, обучения модели
* Progress bars увеличивают удовлетворение больших таймингов, скажем,
  пользователь при виде progress bar подождёт 3 минуты вместо одной
* Доставка сообщение до Марса &mdash; 11 минут

TODO: написать про GPU

## Ссылки

* [What Every Programmer Should Know About Memory](http://www.sgidepot.co.uk/misc/cpumemory.pdf)
* [Discovering Hard Disk Physical Geometry through Microbenchmarking
](http://blog.stuffedcow.net/2019/09/hard-disk-geometry-microbenchmarking/)
* [How Do SSDs work?](https://www.extremetech.com/extreme/210492-extremetech-explains-how-do-ssds-work)
* [User Response Time Limits](https://www.nngroup.com/articles/response-times-3-important-limits/)
* [Reaction time test](https://humanbenchmark.com/tests/reactiontime)